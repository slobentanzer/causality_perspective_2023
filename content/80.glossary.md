## Glossary

### Attention (deep learning)

A mechanism in deep learning that allows the model to focus on specific parts of the input data.
Attention mechanisms are often used in natural language processing to focus on specific words in a sentence, but can also be used in other domains.

### Bias (machine learning)

Bias can be understood in two ways in the context of machine learning.

1. The first definition, and the one predominantly used in this Perspective, is also referred to as statistical bias; a technical term referring to the assumptions made by a model to make predictions.
This bias is a necessary part of any machine learning model.
A model with high bias (low variance) pays very little attention to the training data and oversimplifies the model, which can lead to [underfitting][Underfitting].
This means it does not capture the complexity of the data and fails to learn the underlying patterns effectively.
Conversely, a model with low bias (high variance) makes complex assumptions to fit the data closely, which can lead to [overfitting][Overfitting], where the model captures noise in the data as if it were a true pattern.
See also the [bias-variance tradeoff][Bias-variance tradeoff].

2. The second definition is also known as algorithmic bias, and refers to the systematic and repeatable errors in a model due to faulty assumptions or data.
It often reflect existing biases in the real world that the training data are derived from, but can also result from architectural choices in the model.
As such, algorithmic bias can result from any stage in model training, from data collection to model deployment.

### Bias-variance tradeoff

The concept in machine learning that [bias][Bias (machine learning)] and [variance][Variance (machine learning)] of a model are inversely related.
The term implies that an optimal model finds a balance between bias (impact of the model on predictions) and variance (impact of the data on predictions).
This balance depends on the complexity of model and data.

### Deductive vs. Inductive Reasoning

Deductive reasoning involves drawing specific conclusions from general statements or premises, whereas inductive reasoning involves making broad generalisations from specific observations.
Deductive reasoning is often seen as more logically sound but less informative about the real world, while inductive reasoning is more exploratory but can lead to less certain conclusions.

### Do-Calculus

See Pearl’s Do-Calculus.

### Foundation model

A model that is trained on a large amount of data and can be used as a starting point for further model development (also referred to as fine-tuning).
Foundation models are assumed to have learned generalisable patterns from their input data.
To achieve this, they require large amounts of data and compute power.

### Large Language Models

Large Language Models are advanced AI models trained on extensive text data.
They are capable of understanding and generating human-like text, making them useful in various applications like translation, summarization, and conversation.
LLMs leverage vast amounts of training data to grasp nuances of language, context, and even some elements of human communication.
They are the first commercially successful example of foundation models.

### 'No Free Lunch' Theorems

These theorems in optimization and machine learning suggest that no single algorithm is best for every problem.
The performance of an algorithm is contingent on the specificities of the task and data at hand.
This highlights the importance of choosing or designing algorithms that are well-suited to the particular characteristics of the problem being addressed.
Related to the [bias-variance tradeoff][Bias-variance tradeoff], partly opposed to the [scaling hypothesis][Scaling hypothesis] and [foundation models][Foundation model].

### Overfitting

A technical term referring to a model that captures noise in the data as if it were a true pattern.
Overfitting tends to lead to high performance on the training data but poor performance on the test data.
If a model has overfitted also to the test data, it will also perform poorly on new data, i.e., it will not generalise well.
This is a common occurrence if there has been data leakage between training, validation, and test data.

### Pearl’s Do-Calculus

Developed by Judea Pearl, Do-Calculus is a formal mathematical framework used in causal inference.
It provides a set of rules for calculating the effects of interventions in probabilistic models, allowing researchers to infer causality from observational data.

### Prior knowledge

A term referring to information that is available to inform a learning process.
Often, this is the result of previous research.
The tasks of collecting and integrating prior knowledge are often referred to as knowledge engineering and form a crucial part of model development in systems biology.

### Randomised Clinical Trials

Randomised clinical trials are experiments designed to test the efficacy of medical interventions.
Participants are randomly assigned to groups receiving different treatments, including a control group, which often receives a placebo or gold-standard treatment.
To further minimise confounding factors, participants and administering doctors are often blinded to the treatment given.
This method is considered the gold standard in clinical research for its ability to minimise bias and establish causality between a treatment and its outcomes.

### Scaling hypothesis

The scaling hypothesis posits that the performance of a model increases with the amount of data it is trained on.
Recently, it has come to describe the idea that, given enough data, complex model behaviours can emerge.
The enormous success of current Large Language Models has been attributed to scaling, with emergence of human-like language capabilities around the time of GPT-3.
The ability to scale depends on several factors: the availability of data, parallelisation of training, adequate compute power with a parallel architecture, and a model architecture that can digest large amounts of data effectively.

### Self-supervised learning

A type of machine learning where the model learns from the data itself, without the need for human labelling.
This is achieved by training the model to predict certain properties of the data, such as the next word in a sentence, or the next frame in a video.
Self-supervised learning is often used in the pre-training of [foundation models][Foundation model].
It typically requires a specific mechanism in the model to account for the lack of labelled data, such as the masking applied in the training of [Large Language Models][Large Language Models].

### Structural Causal Models (SCMs)

SCMs are a type of statistical model used to represent and analyse causal relationships.
They consist of variables and equations that describe how these variables interact causally.
SCMs are particularly useful in causal inference as they allow for the analysis of how changes in one variable may cause changes in another.

### Underfitting

A technical term referring to a model that does not capture the complexity of the data.
Underfitting tends to lead to poor performance on both the training and test data.

### Variance (machine learning)

A technical term referring to the sensitivity of a model to the training data.
Describes how much the predictions of a model vary given different training data.
High variance (low bias) in a model can lead to [overfitting][Overfitting] and thus harm generalisation.
Conversely, low variance (high bias) can lead to [underfitting][Underfitting] and thus to a model that does not capture the complexity of the data.
See also the [bias-variance tradeoff][Bias-variance tradeoff].