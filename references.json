[
  {
    "publisher": "Cambridge University Press",
    "abstract": "<jats:p>Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interest to students and professionals in a wide variety of fields. Dr Judea Pearl has received the 2011 Rumelhart Prize for his leading research in Artificial Intelligence (AI) and systems from The Cognitive Science Society.</jats:p>",
    "DOI": "10.1017/cbo9780511803161",
    "source": "Crossref",
    "title": "Causality",
    "author": [
      {
        "given": "Judea",
        "family": "Pearl"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2009,
          9,
          14
        ]
      ]
    },
    "URL": "https://doi.org/ggd72q",
    "id": "peGxtHPM",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1017/cbo9780511803161",
    "type": "entry"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7971",
    "DOI": "10.1038/d41586-023-02361-7",
    "type": "article-journal",
    "page": "686-689",
    "source": "Crossref",
    "title": "ChatGPT broke the Turing test — the race is on for new ways to assess AI",
    "volume": "619",
    "author": [
      {
        "given": "Celeste",
        "family": "Biever"
      }
    ],
    "container-title": "Nature",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          7,
          25
        ]
      ]
    },
    "URL": "https://doi.org/gskd92",
    "container-title-short": "Nature",
    "PMID": "37491395",
    "id": "19EQh1DNG",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/d41586-023-02361-7"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "4",
    "DOI": "10.1038/nmeth.3773",
    "type": "article-journal",
    "page": "310-318",
    "source": "Crossref",
    "title": "Inferring causal molecular networks: empirical assessment through a community-based effort",
    "volume": "13",
    "author": [
      {
        "given": "Steven M",
        "family": "Hill"
      },
      {},
      {
        "given": "Laura M",
        "family": "Heiser"
      },
      {
        "given": "Thomas",
        "family": "Cokelaer"
      },
      {
        "given": "Michael",
        "family": "Unger"
      },
      {
        "given": "Nicole K",
        "family": "Nesser"
      },
      {
        "given": "Daniel E",
        "family": "Carlin"
      },
      {
        "given": "Yang",
        "family": "Zhang"
      },
      {
        "given": "Artem",
        "family": "Sokolov"
      },
      {
        "given": "Evan O",
        "family": "Paull"
      },
      {
        "given": "Chris K",
        "family": "Wong"
      },
      {
        "given": "Kiley",
        "family": "Graim"
      },
      {
        "given": "Adrian",
        "family": "Bivol"
      },
      {
        "given": "Haizhou",
        "family": "Wang"
      },
      {
        "given": "Fan",
        "family": "Zhu"
      },
      {
        "given": "Bahman",
        "family": "Afsari"
      },
      {
        "given": "Ludmila V",
        "family": "Danilova"
      },
      {
        "given": "Alexander V",
        "family": "Favorov"
      },
      {
        "given": "Wai Shing",
        "family": "Lee"
      },
      {
        "given": "Dane",
        "family": "Taylor"
      },
      {
        "given": "Chenyue W",
        "family": "Hu"
      },
      {
        "given": "Byron L",
        "family": "Long"
      },
      {
        "given": "David P",
        "family": "Noren"
      },
      {
        "given": "Alexander J",
        "family": "Bisberg"
      },
      {
        "given": "Gordon B",
        "family": "Mills"
      },
      {
        "given": "Joe W",
        "family": "Gray"
      },
      {
        "given": "Michael",
        "family": "Kellen"
      },
      {
        "given": "Thea",
        "family": "Norman"
      },
      {
        "given": "Stephen",
        "family": "Friend"
      },
      {
        "given": "Amina A",
        "family": "Qutub"
      },
      {
        "given": "Elana J",
        "family": "Fertig"
      },
      {
        "given": "Yuanfang",
        "family": "Guan"
      },
      {
        "given": "Mingzhou",
        "family": "Song"
      },
      {
        "given": "Joshua M",
        "family": "Stuart"
      },
      {
        "given": "Paul T",
        "family": "Spellman"
      },
      {
        "given": "Heinz",
        "family": "Koeppl"
      },
      {
        "given": "Gustavo",
        "family": "Stolovitzky"
      },
      {
        "given": "Julio",
        "family": "Saez-Rodriguez"
      },
      {
        "given": "Sach",
        "family": "Mukherjee"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2016,
          2,
          22
        ]
      ]
    },
    "URL": "https://doi.org/f3t7t4",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC4854847",
    "PMID": "26901648",
    "id": "qpg6x7P4",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/nmeth.3773"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7965",
    "DOI": "10.1038/s41586-023-06139-9",
    "type": "article-journal",
    "page": "616-624",
    "source": "Crossref",
    "title": "Transfer learning enables predictions in network biology",
    "volume": "618",
    "author": [
      {
        "given": "Christina V.",
        "family": "Theodoris"
      },
      {
        "given": "Ling",
        "family": "Xiao"
      },
      {
        "given": "Anant",
        "family": "Chopra"
      },
      {
        "given": "Mark D.",
        "family": "Chaffin"
      },
      {
        "given": "Zeina R.",
        "family": "Al Sayed"
      },
      {
        "given": "Matthew C.",
        "family": "Hill"
      },
      {
        "given": "Helene",
        "family": "Mantineo"
      },
      {
        "given": "Elizabeth M.",
        "family": "Brydon"
      },
      {
        "given": "Zexian",
        "family": "Zeng"
      },
      {
        "given": "X. Shirley",
        "family": "Liu"
      },
      {
        "given": "Patrick T.",
        "family": "Ellinor"
      }
    ],
    "container-title": "Nature",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          5,
          31
        ]
      ]
    },
    "URL": "https://doi.org/gr9x63",
    "container-title-short": "Nature",
    "PMID": "37258680",
    "id": "VmzWBJUJ",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41586-023-06139-9"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "3",
    "DOI": "10.1038/s41587-019-0344-3",
    "type": "article-journal",
    "page": "365-373",
    "source": "Crossref",
    "title": "The functional landscape of the human phosphoproteome",
    "volume": "38",
    "author": [
      {
        "given": "David",
        "family": "Ochoa"
      },
      {
        "given": "Andrew F.",
        "family": "Jarnuczak"
      },
      {
        "given": "Cristina",
        "family": "Viéitez"
      },
      {
        "given": "Maja",
        "family": "Gehre"
      },
      {
        "given": "Margaret",
        "family": "Soucheray"
      },
      {
        "given": "André",
        "family": "Mateus"
      },
      {
        "given": "Askar A.",
        "family": "Kleefeldt"
      },
      {
        "given": "Anthony",
        "family": "Hill"
      },
      {
        "given": "Luz",
        "family": "Garcia-Alonso"
      },
      {
        "given": "Frank",
        "family": "Stein"
      },
      {
        "given": "Nevan J.",
        "family": "Krogan"
      },
      {
        "given": "Mikhail M.",
        "family": "Savitski"
      },
      {
        "given": "Danielle L.",
        "family": "Swaney"
      },
      {
        "given": "Juan A.",
        "family": "Vizcaíno"
      },
      {
        "given": "Kyung-Min",
        "family": "Noh"
      },
      {
        "given": "Pedro",
        "family": "Beltrao"
      }
    ],
    "container-title": "Nature Biotechnology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2019,
          12,
          9
        ]
      ]
    },
    "URL": "https://doi.org/ggd8n7",
    "container-title-short": "Nat Biotechnol",
    "PMCID": "PMC7100915",
    "PMID": "31819260",
    "id": "yCFobrFQ",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41587-019-0344-3"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "8",
    "DOI": "10.1038/s41587-023-01848-y",
    "type": "article-journal",
    "page": "1056-1059",
    "source": "Crossref",
    "title": "Democratizing knowledge representation with BioCypher",
    "volume": "41",
    "author": [
      {
        "given": "Sebastian",
        "family": "Lobentanzer"
      },
      {
        "given": "Patrick",
        "family": "Aloy"
      },
      {
        "given": "Jan",
        "family": "Baumbach"
      },
      {
        "given": "Balazs",
        "family": "Bohar"
      },
      {
        "given": "Vincent J.",
        "family": "Carey"
      },
      {
        "given": "Pornpimol",
        "family": "Charoentong"
      },
      {
        "given": "Katharina",
        "family": "Danhauser"
      },
      {
        "given": "Tunca",
        "family": "Doğan"
      },
      {
        "given": "Johann",
        "family": "Dreo"
      },
      {
        "given": "Ian",
        "family": "Dunham"
      },
      {
        "given": "Elias",
        "family": "Farr"
      },
      {
        "given": "Adrià",
        "family": "Fernandez-Torras"
      },
      {
        "given": "Benjamin M.",
        "family": "Gyori"
      },
      {
        "given": "Michael",
        "family": "Hartung"
      },
      {
        "given": "Charles Tapley",
        "family": "Hoyt"
      },
      {
        "given": "Christoph",
        "family": "Klein"
      },
      {
        "given": "Tamas",
        "family": "Korcsmaros"
      },
      {
        "given": "Andreas",
        "family": "Maier"
      },
      {
        "given": "Matthias",
        "family": "Mann"
      },
      {
        "given": "David",
        "family": "Ochoa"
      },
      {
        "given": "Elena",
        "family": "Pareja-Lorente"
      },
      {
        "given": "Ferdinand",
        "family": "Popp"
      },
      {
        "given": "Martin",
        "family": "Preusse"
      },
      {
        "given": "Niklas",
        "family": "Probul"
      },
      {
        "given": "Benno",
        "family": "Schwikowski"
      },
      {
        "given": "Bünyamin",
        "family": "Sen"
      },
      {
        "given": "Maximilian T.",
        "family": "Strauss"
      },
      {
        "given": "Denes",
        "family": "Turei"
      },
      {
        "given": "Erva",
        "family": "Ulusoy"
      },
      {
        "given": "Dagmar",
        "family": "Waltemath"
      },
      {
        "given": "Judith A. H.",
        "family": "Wodke"
      },
      {
        "given": "Julio",
        "family": "Saez-Rodriguez"
      }
    ],
    "container-title": "Nature Biotechnology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          6,
          19
        ]
      ]
    },
    "URL": "https://doi.org/gszqjr",
    "container-title-short": "Nat Biotechnol",
    "PMID": "37337100",
    "id": "tr1XjZ1R",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41587-023-01848-y"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "10",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>How noncoding DNA determines gene expression in different cell types is a major unsolved problem, and critical downstream applications in human genetics depend on improved solutions. Here, we report substantially improved gene expression prediction accuracy from DNA sequences through the use of a deep learning architecture, called Enformer, that is able to integrate information from long-range interactions (up to 100 kb away) in the genome. This improvement yielded more accurate variant effect predictions on gene expression for both natural genetic variants and saturation mutagenesis measured by massively parallel reporter assays. Furthermore, Enformer learned to predict enhancer–promoter interactions directly from the DNA sequence competitively with methods that take direct experimental data as input. We expect that these advances will enable more effective fine-mapping of human disease associations and provide a framework to interpret <jats:italic>cis</jats:italic>-regulatory evolution.</jats:p>",
    "DOI": "10.1038/s41592-021-01252-x",
    "type": "article-journal",
    "page": "1196-1203",
    "source": "Crossref",
    "title": "Effective gene expression prediction from sequence by integrating long-range interactions",
    "volume": "18",
    "author": [
      {
        "given": "Žiga",
        "family": "Avsec"
      },
      {
        "given": "Vikram",
        "family": "Agarwal"
      },
      {
        "given": "Daniel",
        "family": "Visentin"
      },
      {
        "given": "Joseph R.",
        "family": "Ledsam"
      },
      {
        "given": "Agnieszka",
        "family": "Grabska-Barwinska"
      },
      {
        "given": "Kyle R.",
        "family": "Taylor"
      },
      {
        "given": "Yannis",
        "family": "Assael"
      },
      {
        "given": "John",
        "family": "Jumper"
      },
      {
        "given": "Pushmeet",
        "family": "Kohli"
      },
      {
        "given": "David R.",
        "family": "Kelley"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2021,
          10
        ]
      ]
    },
    "URL": "https://doi.org/gm2wv4",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC8490152",
    "PMID": "34608324",
    "id": "gAQyFCbW",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-021-01252-x"
  },
  {
    "publisher": "Informa UK Limited",
    "issue": "434",
    "DOI": "10.1080/01621459.1996.10476902",
    "type": "article-journal",
    "page": "444-455",
    "source": "Crossref",
    "title": "Identification of Causal Effects Using Instrumental Variables",
    "volume": "91",
    "author": [
      {
        "given": "Joshua D.",
        "family": "Angrist"
      },
      {
        "given": "Guido W.",
        "family": "Imbens"
      },
      {
        "given": "Donald B.",
        "family": "Rubin"
      }
    ],
    "container-title": "Journal of the American Statistical Association",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          1996,
          6
        ]
      ]
    },
    "URL": "https://doi.org/gdz4f4",
    "container-title-short": "Journal of the American Statistical Association",
    "id": "w47lt0ah",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1080/01621459.1996.10476902"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Generative pre-trained models have achieved remarkable success in various domains such as natural language processing and computer vision. Specifically, the combination of large-scale diverse datasets and pre-trained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between linguistic constructs and cellular biology — where texts comprise words, similarly, cells are defined by genes — our study probes the applicability of foundation models to advance cellular biology and genetics research. Utilizing the burgeoning single-cell sequencing data, we have pioneered the construction of a foundation model for single-cell biology, scGPT, which is based on generative pre-trained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT, a generative pre-trained transformer, effectively distills critical biological insights concerning genes and cells. Through the further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell-type annotation, multi-batch integration, multi-omic integration, genetic perturbation prediction, and gene network inference. The scGPT codebase is publicly available at<jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/bowang-lab/scGPT\">https://github.com/bowang-lab/scGPT</jats:ext-link>.</jats:p>",
    "DOI": "10.1101/2023.04.30.538439",
    "type": "manuscript",
    "source": "Crossref",
    "title": "scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI",
    "author": [
      {
        "given": "Haotian",
        "family": "Cui"
      },
      {
        "given": "Chloe",
        "family": "Wang"
      },
      {
        "given": "Hassaan",
        "family": "Maan"
      },
      {
        "given": "Kuan",
        "family": "Pang"
      },
      {
        "given": "Fengning",
        "family": "Luo"
      },
      {
        "given": "Bo",
        "family": "Wang"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          5,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gshk6p",
    "id": "r5y0HbhJ",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.04.30.538439"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>The advent and success of foundation models such as GPT has sparked growing interest in their application to single-cell biology. Models like Geneformer and scGPT have emerged with the promise of serving as versatile tools for this specialized field. However, the efficacy of these models, particularly in zero-shot settings where models are not fine-tuned but used without any further training, remains an open question, especially as practical constraints require useful models to function in settings that preclude fine-tuning (e.g., discovery settings where labels are not fully known). This paper presents a rigorous evaluation of the zero-shot performance of these proposed single-cell foundation models. We assess their utility in tasks such as cell type clustering and batch effect correction, and evaluate the generality of their pretraining objectives. Our results indicate that both Geneformer and scGPT exhibit limited reliability in zero-shot settings and often underperform compared to simpler methods. These findings serve as a cautionary note for the deployment of proposed single-cell foundation models and highlight the need for more focused research to realize their potential.2</jats:p>",
    "DOI": "10.1101/2023.10.16.561085",
    "type": "manuscript",
    "source": "Crossref",
    "title": "Assessing the limits of zero-shot foundation models in single-cell biology",
    "author": [
      {
        "given": "Kasia Z.",
        "family": "Kedzierska"
      },
      {
        "given": "Lorin",
        "family": "Crawford"
      },
      {
        "given": "Ava P.",
        "family": "Amini"
      },
      {
        "given": "Alex X.",
        "family": "Lu"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          10,
          17
        ]
      ]
    },
    "URL": "https://doi.org/gszxk9",
    "id": "WEYqVcYG",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.10.16.561085"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Large-scale foundation models, which are pre-trained on massive, unlabeled datasets and subsequently fine-tuned on specific tasks, have recently achieved unparalleled success on a wide array of applications, including in healthcare and biology. In this paper, we explore two foundation models recently developed for single-cell RNA sequencing data, scBERT and scGPT. Focusing on the fine-tuning task of cell type annotation, we explore the relative performance of pre-trained models compared to a simple baseline, L1-regularized logistic regression, including in the few-shot setting. We perform ablation studies to understand whether pretraining improves model performance and to better understand the difficulty of the pre-training task in scBERT. Finally, using scBERT as an example, we demonstrate the potential sensitivity of fine-tuning to hyperparameter settings and parameter initializations. Taken together, our results highlight the importance of rigorously testing foundation models against well established baselines, establishing challenging fine-tuning tasks on which to benchmark foundation models, and performing deep introspection into the embeddings learned by the model in order to more effectively harness these models to transform single-cell data analysis. Code is available at<jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/clinicalml/sc-foundation-eval\">https://github.com/clinicalml/sc-foundation-eval</jats:ext-link>.</jats:p>",
    "DOI": "10.1101/2023.10.19.563100",
    "type": "manuscript",
    "source": "Crossref",
    "title": "A Deep Dive into Single-Cell RNA Sequencing Foundation Models",
    "author": [
      {
        "given": "Rebecca",
        "family": "Boiarsky"
      },
      {
        "given": "Nalini",
        "family": "Singh"
      },
      {
        "given": "Alejandro",
        "family": "Buendia"
      },
      {
        "given": "Gad",
        "family": "Getz"
      },
      {
        "given": "David",
        "family": "Sontag"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          10,
          23
        ]
      ]
    },
    "URL": "https://doi.org/gszxmb",
    "id": "OFczH7ba",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.10.19.563100"
  },
  {
    "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
    "issue": "5",
    "DOI": "10.1109/jproc.2021.3058954",
    "type": "article-journal",
    "page": "612-634",
    "source": "Crossref",
    "title": "Toward Causal Representation Learning",
    "volume": "109",
    "author": [
      {
        "given": "Bernhard",
        "family": "Scholkopf"
      },
      {
        "given": "Francesco",
        "family": "Locatello"
      },
      {
        "given": "Stefan",
        "family": "Bauer"
      },
      {
        "given": "Nan Rosemary",
        "family": "Ke"
      },
      {
        "given": "Nal",
        "family": "Kalchbrenner"
      },
      {
        "given": "Anirudh",
        "family": "Goyal"
      },
      {
        "given": "Yoshua",
        "family": "Bengio"
      }
    ],
    "container-title": "Proceedings of the IEEE",
    "issued": {
      "date-parts": [
        [
          2021,
          5
        ]
      ]
    },
    "URL": "https://doi.org/gjhqrh",
    "container-title-short": "Proc. IEEE",
    "id": "T7D6XA6s",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/jproc.2021.3058954"
  },
  {
    "publisher": "American Association for the Advancement of Science (AAAS)",
    "issue": "565",
    "abstract": "<jats:p>Identifying the targets of “dark” kinases will provide new biological and disease insights.</jats:p>",
    "DOI": "10.1126/scisignal.aau8645",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Illuminating the dark phosphoproteome",
    "volume": "12",
    "author": [
      {
        "given": "Elise J.",
        "family": "Needham"
      },
      {
        "given": "Benjamin L.",
        "family": "Parker"
      },
      {
        "given": "Timur",
        "family": "Burykin"
      },
      {
        "given": "David E.",
        "family": "James"
      },
      {
        "given": "Sean J.",
        "family": "Humphrey"
      }
    ],
    "container-title": "Science Signaling",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2019,
          1,
          22
        ]
      ]
    },
    "URL": "https://doi.org/gf8c3h",
    "container-title-short": "Sci. Signal.",
    "PMID": "30670635",
    "id": "4VxTzwTj",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1126/scisignal.aau8645"
  },
  {
    "type": "article",
    "id": "rh7nCPVE",
    "categories": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Vaswani",
        "given": "Ashish"
      },
      {
        "family": "Shazeer",
        "given": "Noam"
      },
      {
        "family": "Parmar",
        "given": "Niki"
      },
      {
        "family": "Uszkoreit",
        "given": "Jakob"
      },
      {
        "family": "Jones",
        "given": "Llion"
      },
      {
        "family": "Gomez",
        "given": "Aidan N."
      },
      {
        "family": "Kaiser",
        "given": "Lukasz"
      },
      {
        "family": "Polosukhin",
        "given": "Illia"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
    "DOI": "10.48550/arxiv.1706.03762",
    "publisher": "arXiv",
    "title": "Attention Is All You Need",
    "URL": "https://doi.org/gpnmtv",
    "version": "7",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1706.03762"
  },
  {
    "type": "article-journal",
    "id": "URCTSFCA",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Locatello",
        "given": "Francesco"
      },
      {
        "family": "Bauer",
        "given": "Stefan"
      },
      {
        "family": "Lucic",
        "given": "Mario"
      },
      {
        "family": "Rätsch",
        "given": "Gunnar"
      },
      {
        "family": "Gelly",
        "given": "Sylvain"
      },
      {
        "family": "Schölkopf",
        "given": "Bernhard"
      },
      {
        "family": "Bachem",
        "given": "Olivier"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "abstract": "The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.",
    "container-title": "arXiv",
    "DOI": "10.48550/arxiv.1811.12359",
    "publisher": "arXiv",
    "title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations",
    "URL": "https://doi.org/grx79c",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1811.12359"
  },
  {
    "type": "article",
    "id": "vm2M7mI5",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Aliee",
        "given": "Hananeh"
      },
      {
        "family": "Theis",
        "given": "Fabian J."
      },
      {
        "family": "Kilbertus",
        "given": "Niki"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "abstract": "Spurred by tremendous success in pattern matching and prediction tasks, researchers increasingly resort to machine learning to aid original scientific discovery. Given large amounts of observational data about a system, can we uncover the rules that govern its evolution? Solving this task holds the great promise of fully understanding the causal interactions and being able to make reliable predictions about the system's behavior under interventions. We take a step towards answering this question for time-series data generated from systems of ordinary differential equations (ODEs). While the governing ODEs might not be identifiable from data alone, we show that combining simple regularization schemes with flexible neural ODEs can robustly recover the dynamics and causal structures from time-series data. Our results on a variety of (non)-linear first and second order systems as well as real data validate our method. We conclude by showing that we can also make accurate predictions under interventions on variables or the system itself.",
    "DOI": "10.48550/arxiv.2106.12430",
    "publisher": "arXiv",
    "title": "Beyond Predictions in Neural ODEs: Identification and Interventions",
    "URL": "https://doi.org/gszw4d",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2106.12430"
  },
  {
    "type": "book",
    "id": "YcLevYSc",
    "title": "The Organon, Or Logical Treatises, Of Aristole, Vol. 1 Of 2",
    "author": [
      {
        "literal": "Aristotle"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "ISBN": "9781330267608",
    "publisher": "Forgotten Books",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: isbn:9781330267608"
  },
  {
    "id": "712MuGug",
    "type": "book",
    "abstract": "\"In Myth and Measurement, David Card and Alan Krueger presented a powerful challenge to the conventional view that higher minimum wages necessarily reduce jobs for low-wage workers. In a work that has profoundly influenced public policy as well as the direction of economic research, the authors put standard economic theory to the test, using empirical methods and conducting a critical reexamination of existing literature on the minimum wage. Documenting the effects of the minimum wage on family earnings, poverty outcomes, and the stock market valuation of low-wage employers, they presented a wealth of evidence showing that increases in the minimum wage lead to increases in pay, but no loss in jobs. With a new preface discussing new data, Myth and Measurement continues to shift the terms of the debate on the minimum wage\"--Back cover",
    "edition": "Twentieth-anniversary edition",
    "event-place": "Princeton, New Jersey",
    "ISBN": "9781400880874",
    "language": "eng",
    "note": "OCLC: 928384513\nThis CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: isbn:9781400880874",
    "publisher": "Princeton University Press",
    "publisher-place": "Princeton, New Jersey",
    "source": "Open WorldCat",
    "title": "Myth and measurement: the new economics of the minimum wage",
    "title-short": "Myth and measurement",
    "author": [
      {
        "family": "Card",
        "given": "David E."
      },
      {
        "family": "Krueger",
        "given": "Alan B."
      }
    ],
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    }
  },
  {
    "id": "ydpntqD3",
    "type": "webpage",
    "title": "The Bitter Lesson",
    "URL": "http://www.incompleteideas.net/IncIdeas/BitterLesson.html",
    "accessed": {
      "date-parts": [
        [
          "2023",
          10,
          27
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:http://www.incompleteideas.net/IncIdeas/BitterLesson.html"
  },
  {
    "id": "eT8vyMzx",
    "type": "post-weblog",
    "language": "en-US",
    "title": "A Better Lesson – Rodney Brooks",
    "URL": "https://rodneybrooks.com/a-better-lesson/",
    "accessed": {
      "date-parts": [
        [
          "2023",
          10,
          27
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2019",
          3,
          19
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://rodneybrooks.com/a-better-lesson/"
  },
  {
    "id": "AT0GCO31",
    "type": "webpage",
    "abstract": "Thread by @shimon8282: \"Rich Sutton has a new blog post entitled “The Bitter Lesson” (incompleteideas.net/IncIdeas/Bitte…) that I strongly disagreth. In it, he argues that the history of AI teaches us that leveraging computation always eventually wins out over […]\"",
    "language": "en",
    "title": "Thread by @shimon8282: \"Rich Sutton has a new blog post entitled “The Bitter Lesson” (incompleteideas.net/IncIdeas/Bitte…) that I strongly disagree with. In it, he […]\"",
    "title-short": "Thread by @shimon8282",
    "URL": "https://threadreaderapp.com/thread/1106534178676506624.html",
    "author": [
      {
        "literal": "https://twitter.com/shimon8282"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          10,
          27
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://threadreaderapp.com/thread/1106534178676506624.html"
  }
]
